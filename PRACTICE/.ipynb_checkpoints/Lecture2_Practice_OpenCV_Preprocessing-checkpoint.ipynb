{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0beda3",
   "metadata": {},
   "source": [
    "# Практика: Изображения как данные + базовый препроцессинг (OpenCV)\n",
    "Эта практика повторяет ключевые идеи лекции:\n",
    "- изображение как массив чисел (shape / dtype / range)\n",
    "- BGR vs RGB\n",
    "- resize/crop/pad и сохранение пропорций (letterbox)\n",
    "- нормализация под нейросети\n",
    "- sanity-checks пайплайна\n",
    "\n",
    "Можно запускать последовательно. Никаких баллов — это «песочница»."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba609cd",
   "metadata": {},
   "source": [
    "## 0) Импорты и генерация тестовых изображений\n",
    "Чтобы не тянуть данные из интернета, создадим несколько синтетических картинок прямо в рантайме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIR = Path('data')\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def show(img_rgb, title=None):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.show()\n",
    "\n",
    "# 1) Цветовые блоки (проверка каналов)\n",
    "h, w = 120, 180\n",
    "img = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "# Левый блок красный (в BGR это (0,0,255))\n",
    "img[:, :60]  = (0, 0, 255)\n",
    "# Средний блок зелёный (0,255,0)\n",
    "img[:, 60:120] = (0, 255, 0)\n",
    "# Правый блок синий (255,0,0)\n",
    "img[:, 120:] = (255, 0, 0)\n",
    "cv2.imwrite(str(DATA_DIR / 'color_blocks.png'), img)\n",
    "\n",
    "# 2) Градиент (для resize)\n",
    "h2, w2 = 80, 240\n",
    "x = np.linspace(0, 255, w2, dtype=np.uint8)\n",
    "grad = np.tile(x, (h2, 1))\n",
    "grad_img = np.stack([grad, np.flipud(grad), grad], axis=-1)  # BGR\n",
    "cv2.imwrite(str(DATA_DIR / 'gradient.png'), grad_img)\n",
    "\n",
    "# 3) Текст (для OCR/резкости)\n",
    "txt = np.full((140, 320, 3), 255, dtype=np.uint8)\n",
    "cv2.putText(txt, 'OpenCV', (20, 90), cv2.FONT_HERSHEY_SIMPLEX, 2.2, (0,0,0), 4, cv2.LINE_AA)\n",
    "cv2.imwrite(str(DATA_DIR / 'text.png'), txt)\n",
    "\n",
    "print('Generated:', [p.name for p in DATA_DIR.iterdir()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea0dbaa",
   "metadata": {},
   "source": [
    "## 1) BGR vs RGB\n",
    "OpenCV читает изображение в BGR. Для matplotlib обычно нужен RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd92a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgr = cv2.imread(str(DATA_DIR / 'color_blocks.png'))\n",
    "rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "print('BGR shape:', bgr.shape, 'dtype:', bgr.dtype)\n",
    "print('Pixel left block (BGR):', bgr[0, 10].tolist())\n",
    "print('Pixel left block (RGB):', rgb[0, 10].tolist())\n",
    "show(rgb, 'Correct RGB')\n",
    "# Для контраста — покажем как будет выглядеть, если забыть конвертацию:\n",
    "show(bgr[..., ::-1], 'Same as RGB (manual reverse)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd360a5f",
   "metadata": {},
   "source": [
    "## 2) dtype и диапазоны\n",
    "Частая схема для нейросетей: uint8 (0..255) → float32 (0..1) → (x-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dea7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = cv2.cvtColor(cv2.imread(str(DATA_DIR / 'gradient.png')), cv2.COLOR_BGR2RGB)\n",
    "print('uint8:', img_rgb.dtype, img_rgb.min(), img_rgb.max())\n",
    "img_f = img_rgb.astype(np.float32) / 255.0\n",
    "print('float32:', img_f.dtype, float(img_f.min()), float(img_f.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e98298d",
   "metadata": {},
   "source": [
    "## 3) Resize: ломаем пропорции или сохраняем?\n",
    "Сравним обычный resize и letterbox (resize + pad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca88f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.cvtColor(cv2.imread(str(DATA_DIR / 'text.png')), cv2.COLOR_BGR2RGB)\n",
    "H, W = src.shape[:2]\n",
    "target = (224, 224)\n",
    "\n",
    "# 3.1 Обычный resize (пропорции ломаются)\n",
    "resized = cv2.resize(src, target[::-1], interpolation=cv2.INTER_LINEAR)\n",
    "show(resized, 'Resize to 224x224 (aspect may distort)')\n",
    "\n",
    "# 3.2 Letterbox: сохраняем аспект + pad\n",
    "def letterbox(img_rgb, target_hw=(224,224), pad_value=0):\n",
    "    th, tw = target_hw\n",
    "    h, w = img_rgb.shape[:2]\n",
    "    scale = min(tw / w, th / h)\n",
    "    nw, nh = int(round(w * scale)), int(round(h * scale))\n",
    "    resized = cv2.resize(img_rgb, (nw, nh), interpolation=cv2.INTER_AREA if scale < 1 else cv2.INTER_LINEAR)\n",
    "    out = np.full((th, tw, 3), pad_value, dtype=img_rgb.dtype)\n",
    "    top = (th - nh) // 2\n",
    "    left = (tw - nw) // 2\n",
    "    out[top:top+nh, left:left+nw] = resized\n",
    "    return out, {'scale': scale, 'top': top, 'left': left, 'new_hw': (nh, nw)}\n",
    "\n",
    "lb, info = letterbox(src, target_hw=target, pad_value=128)\n",
    "print('Letterbox info:', info)\n",
    "show(lb, 'Letterbox 224x224 (keeps aspect)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b1c762",
   "metadata": {},
   "source": [
    "## 4) Цветовые пространства\n",
    "HSV иногда удобнее для порогов/стабильности к освещению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dedc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = cv2.cvtColor(cv2.imread(str(DATA_DIR / 'color_blocks.png')), cv2.COLOR_BGR2RGB)\n",
    "hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
    "print('HSV sample pixels:', hsv[0,10].tolist(), hsv[0,80].tolist(), hsv[0,150].tolist())\n",
    "# Покажем канал Hue как изображение\n",
    "plt.figure(figsize=(4,3)); plt.title('Hue channel'); plt.axis('off'); plt.imshow(hsv[...,0], cmap='gray'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d4789",
   "metadata": {},
   "source": [
    "## 5) Шум и фильтры\n",
    "Фильтры могут помогать, но легко убивают детали (особенно текст и мелкие дефекты)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aaf041",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.cvtColor(cv2.imread(str(DATA_DIR / 'text.png')), cv2.COLOR_BGR2RGB)\n",
    "rng = np.random.default_rng(SEED)\n",
    "noise = rng.normal(0, 18, size=src.shape).astype(np.float32)\n",
    "noisy = np.clip(src.astype(np.float32) + noise, 0, 255).astype(np.uint8)\n",
    "blur = cv2.GaussianBlur(noisy, (5,5), 0)\n",
    "show(noisy, 'Noisy')\n",
    "show(blur, 'GaussianBlur(5x5)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c748e7",
   "metadata": {},
   "source": [
    "## 6) Нормализация под нейросети\n",
    "Покажем стандартные ImageNet mean/std и проверим статистики после нормализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b796c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "IMAGENET_STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "img = cv2.cvtColor(cv2.imread(str(DATA_DIR / 'text.png')), cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224,224), interpolation=cv2.INTER_LINEAR)\n",
    "x = img.astype(np.float32)/255.0\n",
    "x = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
    "print('normalized: mean ~', x.mean(axis=(0,1)), 'std ~', x.std(axis=(0,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b861e91",
   "metadata": {},
   "source": [
    "## 7) Мини-пайплайн preprocess(img, mode)\n",
    "Идея: train — случайность, eval — детерминированность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb7ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eval(img_bgr, target_hw=(224,224)):\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_rgb, _ = letterbox(img_rgb, target_hw=target_hw, pad_value=114)\n",
    "    x = img_rgb.astype(np.float32)/255.0\n",
    "    x = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
    "    x = np.transpose(x, (2,0,1))  # CHW\n",
    "    return x\n",
    "\n",
    "bgr = cv2.imread(str(DATA_DIR/'text.png'))\n",
    "x = preprocess_eval(bgr)\n",
    "print('tensor shape:', x.shape, 'dtype:', x.dtype, 'min/max:', float(x.min()), float(x.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94320e58",
   "metadata": {},
   "source": [
    "## 8) Sanity checks\n",
    "Перед обучением всегда делайте проверки shape/dtype/range + смотрите примеры «до/после»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c6cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_report(arr):\n",
    "    a = np.array(arr)\n",
    "    return {\n",
    "        'shape': tuple(a.shape),\n",
    "        'dtype': str(a.dtype),\n",
    "        'min': float(np.min(a)),\n",
    "        'max': float(np.max(a)),\n",
    "        'mean': float(np.mean(a)),\n",
    "        'std': float(np.std(a)),\n",
    "        'has_nan': bool(np.isnan(a).any()) if np.issubdtype(a.dtype, np.floating) else False,\n",
    "    }\n",
    "\n",
    "print(sanity_report(x))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lecture2_Practice_OpenCV_Preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
